{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Week03_Lab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbKQgcSop3Y3"
      },
      "source": [
        "#Uncomment (after line 3)  if you're using colab\n",
        "# Setting up google drive \n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive', force_remount=True)\n",
        "#import sys\n",
        "#sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB2qCFQsp3Y8"
      },
      "source": [
        "%matplotlib inline\n",
        "import my_utils as mu\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InaY5qWbp3Y9"
      },
      "source": [
        "# The Task\n",
        "\n",
        "* Our **Task** for this week is to apply Linear Regression to Sequential Data; in particular to time series. The model that we will develop is a simple *Auto-Regressive* Model which is an widely-used family of models in Machine Learning. \n",
        "* The Learning Outcome: Hands-on application of PyTorch's API for solving Linear Regression.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHJrP-7Yp3Y9"
      },
      "source": [
        "# Data Generation\n",
        "\n",
        "* We generate our sequence data by using a function $x = f(t)$ for time steps $1, 2, \\ldots, 1000$.\n",
        "* We define the function $f(.)$ as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "TXUsuHjTp3Y9"
      },
      "source": [
        "def f(time):\n",
        "    return torch.sin(0.1 * time) * torch.exp(-0.001*time) #+ torch.normal(0, 0.2, (T,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNKFFo11p3Y-"
      },
      "source": [
        "# Run the following code\n",
        "T = 1000  # Generate a total of 1000 points\n",
        "time = torch.arange(1, T + 1, dtype=torch.float32)\n",
        "x = f(time)\n",
        "mu.plot(time, [x], 'time', 'x', xlim=[1, 1000], figsize=(6, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrxqD_c3p3Y-"
      },
      "source": [
        "## Question\n",
        "* Do you expect that a linear model can approximately well the above function?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "G8qcbbrdp3Y-"
      },
      "source": [
        "## Task 1\n",
        "* Your first task is to turn the above sequence into features and labels that we can train our model on.\n",
        "* You should create your dataset as follows: for every time instance $t$, the target (i.e. ground truth label) will be $y_t = x_t$ and the input features $\\mathbf{x}_t = [x_{t-\\tau}, \\ldots, x_{t-1}]$. \n",
        "    * Choose $\\tau=4$ and start from $t=\\tau+1$. So the first (input features, target) pair should be $([x_0, x_1, x_2, x_3], x_4)$, the second $([x_1, x_2, x_3, x_4], x_5)$ and so on.\n",
        "* Store the features in a matrix (using a tensor from `torch`) called `features` so that the first row contains the first input feature, the second row the second input feature and so on. For example `features[0, :]= x_0, x_1, x_2, x_3`.\n",
        "*  Store the labels in a vector (using a tensor from `torch`) called `labels` so that the first element contains the first target, the second row the second label and so on.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "3UHNvfMPp3Y-"
      },
      "source": [
        "# Write your code here to create the two tensors: features and labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l8HwvZYp3Y_"
      },
      "source": [
        "# Might be good idea to check here that the features and labels tensors contain the right data  \n",
        "# What are their dimensions? Make sure that features.size() gives you a matrix of size 994x4 and labels.size() \n",
        "# a vector of size 994x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzB3bARip3Y_"
      },
      "source": [
        "# Task 2\n",
        "* Use `data.TensorDataset` and the previously created matrices to create your dataset. Simply call it `dataset`. \n",
        "    * Use the first `n_train=600` feature-label pairs for training.\n",
        "    * Check lecture slides and `torch` documentation if necessary.\n",
        "* Use `data.DataLoader` to create your dataloader. Pick a reasonable value for the batch size (e.g. `batch_size=16`).\n",
        "    * You can call your dataloader `data_iter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32F5mU0Zp3Y_"
      },
      "source": [
        "# Write your code here to create dataset and data_iter\n",
        "n_train = 600 # number of feature-labels pairs used for training\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2nnEmljp3ZA"
      },
      "source": [
        "# Task 3\n",
        "* This task is about creating, initializing and training a linear net, using PyTorch's API. You have to implement the following 4 steps: \n",
        "    1. Create a simple linear net and initialize it appropriately.\n",
        "    1. Use an MSE loss.\n",
        "    1. From `torch.optim` use Adam (rather than SGD) to create an `optimizer` with a learning rate equal to 0.01.\n",
        "    1. Write a training function with the following signature `train(net, data_iter, loss, optimizer, epochs)` and use it to train your network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVKpQuPbp3ZA"
      },
      "source": [
        "# Write code for defining and initializing your model here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvhhZvhWp3ZA"
      },
      "source": [
        "# Write code for creating the loss and the optimizer here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y9jmDjSp3ZA"
      },
      "source": [
        "# Write code for the training function train(net, data_iter, loss, optimizer, epochs) here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-VXXpoZp3ZB"
      },
      "source": [
        "# Write code for training the model here. This refers to calling the train function. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 18,
        "id": "IllUeGdAp3ZB"
      },
      "source": [
        "## Task 4 \n",
        "\n",
        "* Use the model to *predict* what happens in the next time step. \n",
        "    * This is called *one-step-ahead prediction*.\n",
        "    * Store the output of your model in variable called `onestep_preds` and use the following code to plot the original data and the model's prediction.\n",
        "    * What do you oberve? Can the model predict the output samples correctly? Can you explain why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q21iC3K4p3ZB"
      },
      "source": [
        "# Write code for getting the model's predictions onestep_preds here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juZLSakzp3ZB"
      },
      "source": [
        "# this will not work if the you don't provide onestep_preds :)\n",
        "mu.plot([time, time[tau:]], [mu.numpy(x), mu.numpy(onestep_preds)], 'time',\n",
        "         'x', legend=['data', '1-step preds'], xlim=[1, 1000],\n",
        "         figsize=(6, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNzZzXrNp3ZB"
      },
      "source": [
        "## Task 5\n",
        "* Modify the above code to plot the absolute difference between tha data and the model's prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjS1ET01p3ZC"
      },
      "source": [
        "# Write the modified plot function here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvtTirgYp3ZC"
      },
      "source": [
        "## Task 6\n",
        "\n",
        "* Change the generating function to $x = \\frac{1.0}{1.0 + f(t)}$ and repeat the above mentioned steps.\n",
        "* What do you observe? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LxykyDkp3ZC"
      },
      "source": [
        "## Task 7 -- Optional\n",
        "\n",
        "* Re-run your code with the original generating function to $x = f(t)$.\n",
        "* It turns out that our previous predictions were too good to be true. The reason for this is that after we train the model using the first let's say 600 samples we cannot expect to have the inputs for all one-step-ahead predictions beyond this point.\n",
        "\n",
        "* Instead, we need to work our way forward one step at a time:\n",
        "\n",
        "$$\n",
        "\\hat{x}_{605} = f(x_{601}, x_{602}, x_{603}, x_{604}), \\\\\n",
        "\\hat{x}_{606} = f(x_{602}, x_{603}, x_{604}, \\hat{x}_{605}), \\\\\n",
        "\\hat{x}_{607} = f(x_{603}, x_{604}, \\hat{x}_{605}, \\hat{x}_{606}),\\\\\n",
        "\\hat{x}_{608} = f(x_{604}, \\hat{x}_{605}, \\hat{x}_{606}, \\hat{x}_{607}),\\\\\n",
        "\\hat{x}_{609} = f(\\hat{x}_{605}, \\hat{x}_{606}, \\hat{x}_{607}, \\hat{x}_{608}),\\\\\n",
        "\\ldots\n",
        "$$\n",
        "\n",
        "* In other words, we will have to use our own predictions to make multistep-ahead predictions.\n",
        "* You are tasked to write some code to do this. Store the model's prediction in variable called `multistep_preds`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWPX7Iuip3ZC"
      },
      "source": [
        "# Write the code to obtain the multistep-ahead predictions (multistep_preds) here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA97kqr8p3ZD"
      },
      "source": [
        "## Task 8 -- Optional\n",
        "* Modify the plotting code above to plot the original data, the one step predictions from Task 4 (`onestep_preds`) along with the multistep-ahead predictions from Task 7.\n",
        "* What do you observe? Do you have some explanation for what happens?"
      ]
    }
  ]
}